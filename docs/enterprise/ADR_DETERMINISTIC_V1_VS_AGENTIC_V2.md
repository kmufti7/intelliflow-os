# ADR: Deterministic v1 Architecture vs. Agentic v2 Architecture

## Status

**Accepted** — February 2026

---

## Context

IntelliFlow OS exists in two architectural generations that reflect fundamentally different approaches to LLM integration in regulated environments:

- **v1 (Current — SupportFlow, CareFlow):** Deterministic orchestration. LLMs extract structured data and format human-readable explanations. Deterministic Python code computes all clinical, financial, and compliance decisions. The LLM never decides whether a care gap exists, whether a policy applies, or whether an escalation is warranted.

- **v2 (Planned — Agentic):** Multi-agent orchestration. Agents with defined roles, tool access, and memory coordinate to handle complex workflows. Agents make routing decisions, select tools, and compose multi-step plans — with governance guardrails constraining the decision space.

This ADR documents why these two generations coexist and why v1 modules were not retrofitted with agentic patterns.

The decision is architecturally significant because it determines:

- **Audit trail integrity.** Whether every decision in the pipeline can be traced to a deterministic code path or requires probabilistic reasoning explanation.
- **Regulatory defensibility.** Whether the platform can demonstrate to auditors that clinical and financial decisions are computed by code, not generated by a language model.
- **Deterministic kill-switch mandate.** Whether an operator can disable LLM involvement in the decision pipeline without losing decision-making capability.
- **SR 11-7 model risk alignment.** Whether the architecture separates model outputs (extraction, explanation) from business logic (gap computation, policy routing, escalation decisions) as required by Federal Reserve model risk guidance.

---

## Decision Drivers

### 1. "Code Decides, LLM Explains"

IntelliFlow OS v1 enforces a strict boundary: LLMs are data extraction and explanation formatting tools. They do not make decisions. This principle is not a preference — it is a regulatory requirement for deployments in healthcare (HIPAA audit trails) and banking (SR 11-7 model risk management).

In v1:
- CareFlow: Regex extracts lab values (100% success rate). Python compares A1C 8.2 > 7.0 = gap. LLM formats the explanation with dual citations (patient evidence + guideline evidence).
- SupportFlow: Keyword matching routes queries to policies (60+ keywords → 20 policies). Python computes severity. LLM formats the response with policy citations.

Agentic patterns introduce non-deterministic routing — an agent decides which tool to call, which sub-agent to invoke, or which plan to execute. This routing is not auditable in the same way deterministic code paths are.

### 2. Regulatory Audit Requirements

Regulated industries require decision traceability:

| Requirement | v1 (Deterministic) | v2 (Agentic) |
|-------------|---------------------|---------------|
| **HIPAA audit trail** | Every decision traces to a Python code path. Auditor can inspect the exact comparison that triggered a care gap. | Agent routing decisions are probabilistic. Audit trail includes agent reasoning, but the decision path is not deterministic. |
| **SR 11-7 model risk** | Model outputs (extraction) are separated from business logic (gap computation). Model risk is isolated to the extraction layer. | Agent routing conflates model outputs with business logic. Model risk extends to the decision layer. |
| **EU AI Act record-keeping** | Decision logic is inspectable Python code. Explanation of decisions is straightforward. | Agent plans and tool selections require explanation of probabilistic reasoning. Compliance documentation is more complex. |

### 3. Deterministic Kill-Switch

v1 modules can operate with the LLM completely disabled:
- CareFlow: Regex extraction succeeds on all test patients. Gap computation runs without LLM. Only the explanation formatting is lost.
- SupportFlow: Keyword routing succeeds without LLM. Policy retrieval and severity computation are deterministic. Only the natural language response formatting is lost.

Agentic architectures cannot provide this guarantee. If the agent is the orchestrator, disabling the LLM disables the workflow.

---

## Options Evaluated

### Option A: Retrofit v1 Modules with Agentic Patterns (Rejected)

Replace v1's deterministic orchestrators with agentic orchestrators while preserving existing business logic as tools the agent can invoke.

| Attribute | Detail |
|-----------|--------|
| **Migration effort** | Moderate. Existing business logic becomes tool functions. New agent orchestrator wraps existing pipeline. |
| **Audit trail impact** | Breaking change. Decision paths become probabilistic. Existing audit trail guarantees are lost. |
| **Kill-switch** | Lost. Agent becomes the orchestrator — disabling the LLM disables the workflow. |
| **Regulatory risk** | High. Existing compliance documentation (HIPAA audit trail, SR 11-7 separation) becomes invalid. Must re-document and re-validate. |
| **Customer impact** | Operators who deployed v1 for its deterministic guarantees lose those guarantees. |

**Rejection rationale:** Retrofitting destroys the property that makes v1 deployable in regulated environments. The deterministic decision path is not a limitation to be removed — it is the value proposition.

### Option B: Keep v1 as Reference Implementations, Build v2 Agentic-Native (Selected)

v1 modules (SupportFlow, CareFlow) remain deterministic reference implementations. v2 modules are built from scratch with agentic orchestration, governance guardrails, and a different audit trail model designed for probabilistic decision paths.

| Attribute | Detail |
|-----------|--------|
| **Migration effort** | None for v1. v2 is a new development effort with shared SDK (intelliflow-core). |
| **Audit trail impact** | No change to v1. v2 introduces a new audit model: agent reasoning traces with governance checkpoints. |
| **Kill-switch** | Preserved in v1. v2 implements guardrail-based constraints instead of kill-switch (agent decisions are bounded, not eliminated). |
| **Regulatory risk** | None for v1. v2 compliance documentation is built fresh for agentic patterns. |
| **Customer impact** | Operators choose: v1 for deterministic guarantees, v2 for agentic flexibility. No forced migration. |

**Selection rationale:** This option preserves v1's regulatory defensibility while enabling v2 innovation. The shared SDK (intelliflow-core) ensures both generations share governance primitives (audit schemas, cost tracking, Pydantic contracts).

### Option C: Full Rewrite of All Modules (Rejected)

Discard v1 modules entirely. Rebuild SupportFlow and CareFlow as agentic-native implementations.

| Attribute | Detail |
|-----------|--------|
| **Migration effort** | High. Complete rewrite of two production-validated modules. |
| **Audit trail impact** | Breaking change for all existing deployments. |
| **Kill-switch** | Lost permanently. No deterministic fallback available. |
| **Regulatory risk** | Very high. All existing compliance documentation, test suites (193 tests), and enterprise evidence (17 docs, 59 checks) apply to v1 architecture. Rewrite invalidates all of it. |
| **Customer impact** | Operators lose access to deterministic modules. No migration path — only replacement. |

**Rejection rationale:** Destroys 193 tests, 17 enterprise documents, and 59 verification checks worth of validated compliance infrastructure. The rewrite provides no incremental regulatory benefit over Option B and introduces significant regression risk.

---

## Cost and Risk Comparison

| Dimension | v1 (Deterministic) | v2 (Agentic) |
|-----------|---------------------|---------------|
| **Decision model** | Python code computes decisions. LLM extracts and explains. | Agent selects tools and routes. Guardrails constrain the decision space. |
| **Audit trail** | Deterministic code path. Every decision traces to a specific Python comparison. | Agent reasoning trace with governance checkpoints. Decision path is bounded but probabilistic. |
| **Regulatory defensibility** | High. "The code decided, here's the line." Auditors can inspect the exact logic. | Moderate. "The agent decided within these guardrails." Requires explanation of constraint model. |
| **Kill-switch capability** | Full. LLM can be disabled without losing decision capability. | Partial. Agent can be constrained but not disabled without losing orchestration. |
| **Operational complexity** | Low. Deterministic pipelines with well-defined failure modes. Chaos engineering validates fallback paths. | Higher. Agent behavior is emergent. Testing requires scenario coverage, not just unit/integration tests. |
| **Flexibility** | Low. New workflows require new deterministic pipelines. | High. Agents adapt to novel inputs within guardrail boundaries. |
| **Time to new workflow** | Days to weeks. Pipeline design, implementation, testing, documentation. | Hours to days. Agent configuration, guardrail definition, validation. |
| **SR 11-7 alignment** | Strong. Model outputs separated from business logic. Model risk isolated to extraction layer. | Requires mitigation. Agent routing conflates model output with business logic. Guardrail documentation addresses this. |
| **Test strategy** | Unit + integration + chaos. 193 tests validate deterministic behavior. | Scenario-based + adversarial + guardrail boundary. Requires different testing methodology. |
| **Enterprise evidence reuse** | Full. All 17 docs and 59 checks apply directly. | Partial. Governance framework (NIST AI RMF, OWASP) applies. Module-specific evidence requires new documentation. |

---

## Consequences

### Positive

- **v1 regulatory posture is preserved.** SupportFlow and CareFlow retain their deterministic guarantees. Operators who deployed for compliance auditability are unaffected.
- **v2 can innovate without constraint.** Agentic patterns are designed from scratch, not shoehorned into a deterministic architecture. Governance guardrails are native, not retrofitted.
- **Shared SDK provides continuity.** Both generations import intelliflow-core. Audit schemas, cost tracking, and Pydantic contracts are shared. Governance primitives do not diverge.
- **Customer choice, not forced migration.** Operators select the generation that matches their regulatory requirements. Deterministic and agentic modules can coexist in the same deployment.
- **Test and documentation investment is protected.** 193 tests and 17 enterprise documents remain valid for v1. v2 builds on the governance framework without invalidating existing evidence.

### Negative

- **Two architectural patterns to maintain.** v1 (deterministic pipelines) and v2 (agentic orchestration) require different operational knowledge, testing strategies, and documentation approaches.
- **v1 modules will not receive agentic capabilities.** SupportFlow and CareFlow will not gain multi-step reasoning, tool selection, or adaptive routing. They remain deterministic by design.
- **SDK must serve both patterns.** intelliflow-core must provide governance primitives that work for deterministic pipelines and agentic orchestration. This constrains SDK design — new primitives must be pattern-agnostic.
- **Documentation complexity increases.** Enterprise evidence must distinguish between v1 and v2 compliance postures. Operators need clarity on which guarantees apply to which generation.

---

## References

| Reference | Relevance |
|-----------|-----------|
| [SR 11-7: Guidance on Model Risk Management](https://www.federalreserve.gov/supervisionreg/srletters/sr1107.htm) | Federal Reserve guidance requiring separation of model outputs from business decisions. v1's "code decides, LLM explains" directly addresses this. |
| [HIPAA Security Rule — Audit Controls (§164.312(b))](https://www.hhs.gov/hipaa/for-professionals/security/laws-regulations/index.html) | Requires audit trails for access to electronic PHI. v1's deterministic code paths provide traceable decision logs. |
| [NIST AI RMF — GOVERN function](https://www.nist.gov/artificial-intelligence/risk-management-framework) | Governance controls for AI systems. Both v1 and v2 implement GOVERN function requirements through different mechanisms. |
| [EU AI Act — Article 14 (Human Oversight)](https://eur-lex.europa.eu/eli/reg/2024/1689/oj) | Requires human oversight of high-risk AI systems. v1's kill-switch capability directly enables this. v2 uses guardrail-based constraints. |
| [OWASP LLM Top 10](https://owasp.org/www-project-top-10-for-large-language-model-applications/) | LLM-specific security risks. v1 mitigates LLM01 (prompt injection) by limiting LLM authority. v2 requires additional guardrail mitigations. |

---

*Apache 2.0 — Copyright 2025-2026 Kaizen Works, LLC*
