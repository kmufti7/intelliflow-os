#!/usr/bin/env python3
"""
verify_cascade.py â€” Verifies that all platform files are consistent.

Checks:
1. Every "Built" story in CLAUDE.md has substance in all 8 portfolio files
2. Numbers in portfolio files match portfolio_config.yaml
3. No forbidden phrases in any portfolio, README, or enterprise doc
4. ARCHITECTURE.md has Mermaid diagrams for each module
5. CHANGELOG.md has recent entries (flags staleness > 30 days)
6. verify_enterprise_docs.py passes
"""

import io
import os
import re
import sys
import yaml
import subprocess
from pathlib import Path
from datetime import datetime, timedelta

# Fix Windows console encoding for emoji/unicode
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8", errors="replace")

REPO_ROOT = Path(__file__).parent.parent
CONFIG_PATH = REPO_ROOT / "portfolio_config.yaml"
CLAUDE_MD = REPO_ROOT / "CLAUDE.md"
PORTFOLIO_DIR = REPO_ROOT / "portfolio_writeup"
ARCHITECTURE_MD = REPO_ROOT / "ARCHITECTURE.md"
CHANGELOG_MD = REPO_ROOT / "CHANGELOG.md"

# Files to check for forbidden phrases (exclude PRIVATE_CHANGELOG â€” it's a log file)
CHECK_FILES = [
    f for f in PORTFOLIO_DIR.glob("*.md")
    if "PRIVATE_CHANGELOG" not in f.name and "template" not in f.name.lower()
] + [
    REPO_ROOT / "linkedin_experience.md",
    REPO_ROOT / "README.md",
    ARCHITECTURE_MD,
]

# Story-specific terms: if a story is "Built", these terms should appear
# in portfolio files (at least some of them, in most files)
STORY_TERMS = {
    "A": ["deterministic", "LLM extracts", "code decides", "Therefore"],
    "B": ["PHI", "data residency", "FAISS", "Pinecone", "local.*cloud"],
    "C": ["platform", "intelliflow-core", "pip", "shared SDK", "Pydantic"],
    "D": ["cost", "regex-first", "gpt-4o-mini", "token tracking", "5 layers"],
    "E": ["front-door bypass", "ChaosError", "analyze_patient", "silent catch", "single entry point"],
    "F": ["tests that lie", "integration test", "12.*unit", "3 integration", "real entry point"],
    "G": ["chaos mode", "resilience", "failure injection", "graceful", "audit"],
    "H": ["FHIR", "dual-mode", "LOINC", "4548-4", "adapter pattern", "Bundle"],
    "I": ["enterprise", "11 docs", "59.*checks", "NIST", "OWASP", "verify_enterprise"],
    "J": ["AI test generator", "schema-aware", "35.*generated", "Pydantic.*test", "edge-case"],
    "K": ["NL log query", "natural language.*log", "SQL WHERE"],
    "L": ["scaffold generator", "boilerplate", "ast.parse"],
}

FORBIDDEN_PHRASES = [
    "portfolio project",
    "2 developer tools",
    "intelliflow-core/tools/",
    "SupportFlow uses vector search",
    "SupportFlow uses FAISS",
    "The LLM decides if there's a care gap",
    "AI-powered gap detection",
]


def load_config():
    with open(CONFIG_PATH) as f:
        return yaml.safe_load(f).get("metrics", {})


def read_file(path):
    """Read a file with UTF-8 encoding (handles Windows default cp1252 issues)."""
    return path.read_text(encoding="utf-8")


def get_built_stories():
    """Parse CLAUDE.md to find stories marked as Built."""
    content = read_file(CLAUDE_MD)
    built = []
    for line in content.split("\n"):
        match = re.match(r"\|\s*([A-L])\s*\|.*\|\s*.*Built", line)
        if match and "NOT BUILT" not in line:
            built.append(match.group(1))
    return built


def get_not_built_stories():
    """Parse CLAUDE.md to find stories marked as NOT BUILT."""
    content = read_file(CLAUDE_MD)
    not_built = []
    for line in content.split("\n"):
        match = re.match(r"\|\s*([A-L])\s*\|.*NOT\s*BUILT", line)
        if match:
            not_built.append(match.group(1))
    return not_built


def check_story_substance(built_stories):
    """Check that built stories appear substantively in portfolio files."""
    issues = []
    portfolio_files = sorted(PORTFOLIO_DIR.glob("*.md"))
    portfolio_files = [f for f in portfolio_files if "template" not in str(f)]

    for story_id in built_stories:
        terms = STORY_TERMS.get(story_id, [])
        if not terms:
            continue

        files_with_substance = 0
        for pf in portfolio_files:
            content = pf.read_text(encoding="utf-8", errors="replace").lower()
            # Count how many story-specific terms appear
            matches = sum(1 for t in terms if re.search(t.lower(), content))
            if matches >= 2:  # At least 2 terms = substantive
                files_with_substance += 1

        if files_with_substance < 6:  # Should be in at least 6 of 8 files
            issues.append(
                f"Story {story_id}: only found in {files_with_substance}/8 portfolio files "
                f"(need 6+). Terms checked: {terms[:3]}..."
            )

    return issues


def check_not_built_absent(not_built_stories):
    """Check that NOT BUILT stories don't appear in portfolio files."""
    issues = []
    portfolio_files = sorted(PORTFOLIO_DIR.glob("*.md"))
    portfolio_files = [f for f in portfolio_files if "template" not in str(f)]

    for story_id in not_built_stories:
        terms = STORY_TERMS.get(story_id, [])
        if not terms:
            continue

        for pf in portfolio_files:
            content = pf.read_text(encoding="utf-8").lower()
            for term in terms:
                if re.search(term.lower(), content):
                    issues.append(
                        f"Story {story_id} (NOT BUILT) referenced in {pf.name}: found '{term}'"
                    )
                    break  # One match per file is enough to flag

    return issues


def check_forbidden_phrases():
    """Check for forbidden phrases in all checked files."""
    issues = []
    for filepath in CHECK_FILES:
        if not filepath.exists():
            continue
        content = filepath.read_text(encoding="utf-8")
        for phrase in FORBIDDEN_PHRASES:
            if phrase.lower() in content.lower():
                issues.append(f"Forbidden phrase '{phrase}' found in {filepath.name}")
    return issues


def check_numbers_match(metrics):
    """Check that key numbers in portfolio files match config.

    Only flags numbers that claim to be the TOTAL (e.g., '164 tests passing').
    Sub-counts like '28 chaos tests' or '35 AI-generated' are not flagged.
    """
    issues = []
    # Patterns that indicate a TOTAL claim (not sub-counts like "13 tests pass")
    patterns = {
        "total_tests": [
            r"(\d+)\s*total\s*tests",
            r"(\d+)\s*tests?\s*(?:across the platform|platform-wide|end.to.end)",
        ],
        "enterprise_docs": [
            r"(\d+)\s*enterprise\s*docs",
            r"(\d+)-document\s*(?:Enterprise|Evidence)",
        ],
        "verification_checks": [
            r"(\d+)\s*(?:automated\s*)?verification\s*checks",
            r"(\d+)\s*(?:verification\s*|automated\s*)?checks\s*(?:that|validate|verify)",
        ],
    }

    portfolio_files = sorted(PORTFOLIO_DIR.glob("*.md"))
    portfolio_files = [
        f for f in portfolio_files
        if "template" not in f.name.lower() and "PRIVATE_CHANGELOG" not in f.name
    ]

    for filepath in portfolio_files:
        content = filepath.read_text(encoding="utf-8")
        for metric_key, regex_list in patterns.items():
            expected = str(metrics.get(metric_key, ""))
            if not expected:
                continue
            for regex in regex_list:
                for match in re.finditer(regex, content, re.IGNORECASE):
                    found = match.group(1)
                    if found != expected:
                        issues.append(
                            f"{filepath.name}: {metric_key} expected '{expected}' found '{found}'"
                        )
    return issues


def check_architecture_diagrams():
    """Check ARCHITECTURE.md has Mermaid diagrams."""
    issues = []
    if not ARCHITECTURE_MD.exists():
        issues.append("ARCHITECTURE.md does not exist")
        return issues

    content = ARCHITECTURE_MD.read_text(encoding="utf-8")
    mermaid_count = content.lower().count("```mermaid")

    if mermaid_count < 3:
        issues.append(
            f"ARCHITECTURE.md has {mermaid_count} Mermaid diagrams (expected 3+: platform, SupportFlow, CareFlow)"
        )

    # Check for key components in diagrams
    checks = {
        "CareFlow": "careflow" in content.lower(),
        "SupportFlow": "supportflow" in content.lower(),
        "FAISS": "faiss" in content.lower(),
        "Pinecone": "pinecone" in content.lower(),
    }

    for component, found in checks.items():
        if not found:
            issues.append(f"ARCHITECTURE.md missing reference to {component}")

    return issues


def check_changelog_freshness():
    """Check CHANGELOG.md has a recent entry."""
    issues = []
    if not CHANGELOG_MD.exists():
        issues.append("CHANGELOG.md does not exist")
        return issues

    content = CHANGELOG_MD.read_text(encoding="utf-8")
    # Look for date patterns (YYYY-MM-DD or Month Day, Year)
    dates = re.findall(r"(\d{4}-\d{2}-\d{2})", content)

    if not dates:
        issues.append("CHANGELOG.md has no date entries")
        return issues

    latest = max(dates)
    latest_date = datetime.strptime(latest, "%Y-%m-%d")
    days_ago = (datetime.now() - latest_date).days

    if days_ago > 30:
        issues.append(
            f"CHANGELOG.md last entry is {latest} ({days_ago} days ago). May be stale."
        )

    return issues


def run_enterprise_verification():
    """Run verify_enterprise_docs.py if it exists."""
    script = REPO_ROOT / "scripts" / "verify_enterprise_docs.py"
    if not script.exists():
        return ["verify_enterprise_docs.py not found"]

    try:
        result = subprocess.run(
            [sys.executable, str(script)],
            capture_output=True,
            text=True,
            cwd=str(REPO_ROOT),
            timeout=60,
        )
        if result.returncode != 0:
            return [f"verify_enterprise_docs.py failed:\n{result.stdout}\n{result.stderr}"]
    except subprocess.TimeoutExpired:
        return ["verify_enterprise_docs.py timed out (60s)"]

    return []


def main():
    print("=" * 60)
    print("VERIFY CASCADE â€” IntelliFlow OS Consistency Check")
    print("=" * 60)

    metrics = load_config()
    all_issues = []
    checks_run = 0
    checks_passed = 0

    # 1. Story substance
    print("\nğŸ“– Checking story substance in portfolio files...")
    checks_run += 1
    built = get_built_stories()
    issues = check_story_substance(built)
    if issues:
        all_issues.extend(issues)
        for i in issues:
            print(f"  âŒ {i}")
    else:
        checks_passed += 1
        print(f"  âœ… All {len(built)} built stories have substance in portfolio files")

    # 2. NOT BUILT stories absent
    print("\nğŸš« Checking NOT BUILT stories are absent from portfolio files...")
    checks_run += 1
    not_built = get_not_built_stories()
    issues = check_not_built_absent(not_built)
    if issues:
        all_issues.extend(issues)
        for i in issues:
            print(f"  âŒ {i}")
    else:
        checks_passed += 1
        print(f"  âœ… {len(not_built)} NOT BUILT stories correctly absent")

    # 3. Forbidden phrases
    print("\nğŸš· Checking forbidden phrases...")
    checks_run += 1
    issues = check_forbidden_phrases()
    if issues:
        all_issues.extend(issues)
        for i in issues:
            print(f"  âŒ {i}")
    else:
        checks_passed += 1
        print(f"  âœ… No forbidden phrases found")

    # 4. Numbers match
    print("\nğŸ”¢ Checking numbers match portfolio_config.yaml...")
    checks_run += 1
    issues = check_numbers_match(metrics)
    if issues:
        all_issues.extend(issues)
        for i in issues:
            print(f"  âŒ {i}")
    else:
        checks_passed += 1
        print(f"  âœ… All numbers match config")

    # 5. Architecture diagrams
    print("\nğŸ“ Checking ARCHITECTURE.md diagrams...")
    checks_run += 1
    issues = check_architecture_diagrams()
    if issues:
        all_issues.extend(issues)
        for i in issues:
            print(f"  âš ï¸  {i}")
    else:
        checks_passed += 1
        print(f"  âœ… ARCHITECTURE.md has required diagrams")

    # 6. CHANGELOG freshness
    print("\nğŸ“… Checking CHANGELOG.md freshness...")
    checks_run += 1
    issues = check_changelog_freshness()
    if issues:
        all_issues.extend(issues)
        for i in issues:
            print(f"  âš ï¸  {i}")
    else:
        checks_passed += 1
        print(f"  âœ… CHANGELOG.md is current")

    # 7. Enterprise docs verification
    print("\nğŸ“‹ Running verify_enterprise_docs.py...")
    checks_run += 1
    issues = run_enterprise_verification()
    if issues:
        all_issues.extend(issues)
        for i in issues:
            print(f"  âŒ {i}")
    else:
        checks_passed += 1
        print(f"  âœ… Enterprise docs verification passed (59/59)")

    # Summary
    print("\n" + "=" * 60)
    print(f"RESULT: {checks_passed}/{checks_run} checks passed")
    if all_issues:
        print(f"\n{len(all_issues)} issues found:")
        for i, issue in enumerate(all_issues, 1):
            print(f"  {i}. {issue}")
        print("\nFix these issues and run again.")
        sys.exit(1)
    else:
        print("\nâœ… All checks passed. Platform files are consistent.")
        sys.exit(0)


if __name__ == "__main__":
    main()
